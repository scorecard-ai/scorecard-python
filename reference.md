# Reference
## Testset
<details><summary><code>client.testset.<a href="src/scorecard/testset/client.py">get</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve Testset metadata without Testcase data
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testset.get(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testset.<a href="src/scorecard/testset/client.py">delete</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Delete a Testset
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testset.delete(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to delete.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testset.<a href="src/scorecard/testset/client.py">update</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Update a Testset.
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testset.update(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to update.
    
</dd>
</dl>

<dl>
<dd>

**name:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**description:** `typing.Optional[str]` â€” A description for the testset.
    
</dd>
</dl>

<dl>
<dd>

**using_retrieval:** `typing.Optional[bool]` â€” Whether or not the testset uses retrieval.
    
</dd>
</dl>

<dl>
<dd>

**custom_schema:** `typing.Optional[CustomSchema]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testset.<a href="src/scorecard/testset/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Create a new Testset
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testset.create(
    name="name",
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**name:** `str` 
    
</dd>
</dl>

<dl>
<dd>

**description:** `typing.Optional[str]` â€” A description for the testset.
    
</dd>
</dl>

<dl>
<dd>

**using_retrieval:** `typing.Optional[bool]` â€” Whether or not the testset uses retrieval.
    
</dd>
</dl>

<dl>
<dd>

**custom_schema:** `typing.Optional[CustomSchema]` 
    
</dd>
</dl>

<dl>
<dd>

**project_id:** `typing.Optional[int]` â€” The ID of the project to create the testset in. Omitting this optional argument will create the testset inside your Organization's default project.
    
</dd>
</dl>

<dl>
<dd>

**ingestion_method:** `typing.Optional[IngestionMethod]` â€” The method of ingestion for the testset.
    
</dd>
</dl>

<dl>
<dd>

**published:** `typing.Optional[bool]` â€” Whether or not the testset is published.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testset.<a href="src/scorecard/testset/client.py">read_schema</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Read the schema of a Testset
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testset.read_schema(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to retrieve the schema from.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testset.<a href="src/scorecard/testset/client.py">get_testcases</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve all Testcases from a Testset
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testset.get_testcases(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The Testset ID to retrieve testcases from.
    
</dd>
</dl>

<dl>
<dd>

**offset:** `typing.Optional[int]` â€” The offset to start from.
    
</dd>
</dl>

<dl>
<dd>

**limit:** `typing.Optional[int]` â€” The number of testcases to return.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Testcase
<details><summary><code>client.testcase.<a href="src/scorecard/testcase/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Create a new Testcase
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testcase.create(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to create the Testcase in.
    
</dd>
</dl>

<dl>
<dd>

**user_query:** `typing.Optional[str]` â€” The user query to be executed.
    
</dd>
</dl>

<dl>
<dd>

**context:** `typing.Optional[str]` â€” The context to be used while generating the testcase.
    
</dd>
</dl>

<dl>
<dd>

**ideal:** `typing.Optional[str]` â€” The ideal response to the user query.
    
</dd>
</dl>

<dl>
<dd>

**custom_inputs:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestcaseCreateParamsCustomInputsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**custom_labels:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestcaseCreateParamsCustomLabelsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testcase.<a href="src/scorecard/testcase/client.py">get</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve Testcase data
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testcase.get(
    testcase_id=1,
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testcase_id:** `int` â€” The ID of the Testcase to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to retrieve the Testcase from.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testcase.<a href="src/scorecard/testcase/client.py">delete</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Delete a Testcase
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testcase.delete(
    testcase_id=1,
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testcase_id:** `int` â€” The ID of the Testcase to delete.
    
</dd>
</dl>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to delete the Testcase from.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testcase.<a href="src/scorecard/testcase/client.py">update</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Update a Testcase.
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testcase.update(
    testcase_id=1,
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testcase_id:** `int` â€” The ID of the Testcase to update.
    
</dd>
</dl>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to retrieve the Testcase from.
    
</dd>
</dl>

<dl>
<dd>

**user_query:** `typing.Optional[str]` â€” The user query to be executed.
    
</dd>
</dl>

<dl>
<dd>

**context:** `typing.Optional[str]` â€” The context to be used while generating the testcase.
    
</dd>
</dl>

<dl>
<dd>

**ideal:** `typing.Optional[str]` â€” The ideal response to the user query.
    
</dd>
</dl>

<dl>
<dd>

**custom_inputs:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestcaseUpdateParamsCustomInputsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**custom_labels:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestcaseUpdateParamsCustomLabelsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testcase.<a href="src/scorecard/testcase/client.py">batch_copy</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Batch copy Testcases
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testcase.batch_copy(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset to create the Testcase in.
    
</dd>
</dl>

<dl>
<dd>

**ids:** `typing.Optional[typing.Sequence[int]]` â€” List of Testcase IDs to copy.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testcase.<a href="src/scorecard/testcase/client.py">batch_delete</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Batch delete Testcases
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testcase.batch_delete(
    testset_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `int` â€” The ID of the Testset from which the Testcases will be deleted.
    
</dd>
</dl>

<dl>
<dd>

**ids:** `typing.Optional[typing.Sequence[int]]` â€” List of Testcase IDs to delete.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Testrecord
<details><summary><code>client.testrecord.<a href="src/scorecard/testrecord/client.py">get</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve Testrecord metadata
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testrecord.get(
    testrecord_id=1,
    run_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testrecord_id:** `int` 
    
</dd>
</dl>

<dl>
<dd>

**run_id:** `int` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.testrecord.<a href="src/scorecard/testrecord/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Create a new Testrecord
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.testrecord.create(
    run_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**run_id:** `int` â€” The ID of the Run to create the Testrecord in.
    
</dd>
</dl>

<dl>
<dd>

**testset_id:** `typing.Optional[int]` 
    
</dd>
</dl>

<dl>
<dd>

**testcase_id:** `typing.Optional[int]` 
    
</dd>
</dl>

<dl>
<dd>

**user_query:** `typing.Optional[str]` â€” The user query that was executed for the testrecord.
    
</dd>
</dl>

<dl>
<dd>

**context:** `typing.Optional[str]` â€” The context that was used while generating the testrecord.
    
</dd>
</dl>

<dl>
<dd>

**response:** `typing.Optional[str]` â€” The response generated by the model.
    
</dd>
</dl>

<dl>
<dd>

**ideal:** `typing.Optional[str]` â€” The ideal response.
    
</dd>
</dl>

<dl>
<dd>

**custom_inputs:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestrecordCreateParamsCustomInputsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**custom_outputs:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestrecordCreateParamsCustomOutputsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**custom_labels:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestrecordCreateParamsCustomLabelsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**prompt:** `typing.Optional[str]` â€” The prompt used to generate the response.
    
</dd>
</dl>

<dl>
<dd>

**model_params:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestrecordCreateParamsModelParamsValue]]
]` â€” The model parameters used to generate the response.
    
</dd>
</dl>

<dl>
<dd>

**model_debug_info:** `typing.Optional[
    typing.Dict[str, typing.Optional[TestrecordCreateParamsModelDebugInfoValue]]
]` â€” Debug information generated by Scorecard during the execution of the testrecord.
    
</dd>
</dl>

<dl>
<dd>

**error_message:** `typing.Optional[str]` â€” The error message for the testrecord.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Run
<details><summary><code>client.run.<a href="src/scorecard/run/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Create a new Run
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.run.create()

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**testset_id:** `typing.Optional[int]` 
    
</dd>
</dl>

<dl>
<dd>

**scoring_config_id:** `typing.Optional[int]` 
    
</dd>
</dl>

<dl>
<dd>

**status:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**model_params:** `typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]` â€” Optional. The model parameters to use for this run.
    
</dd>
</dl>

<dl>
<dd>

**source:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**notes:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**prompt_template:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**metrics:** `typing.Optional[typing.Sequence[int]]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.run.<a href="src/scorecard/run/client.py">get</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve a Run metadata
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.run.get(
    run_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**run_id:** `int` â€” The id of the run to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.run.<a href="src/scorecard/run/client.py">update_status</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Update the status of a run.
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.run.update_status(
    run_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**run_id:** `int` â€” The id of the run to update.
    
</dd>
</dl>

<dl>
<dd>

**status:** `typing.Optional[RunStatus]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Score
<details><summary><code>client.score.<a href="src/scorecard/score/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Create a score
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.score.create(
    run_id=1,
    testrecord_id=1,
    metric_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**run_id:** `int` â€” The ID of the run that created the testrecord to be scored.
    
</dd>
</dl>

<dl>
<dd>

**testrecord_id:** `int` â€” The ID of the testrecord to be scored.
    
</dd>
</dl>

<dl>
<dd>

**metric_id:** `int` â€” The ID of the metric
    
</dd>
</dl>

<dl>
<dd>

**int_score:** `typing.Optional[int]` â€” Specify integer scores.
    
</dd>
</dl>

<dl>
<dd>

**binary_score:** `typing.Optional[bool]` â€” Specify boolean scores.
    
</dd>
</dl>

<dl>
<dd>

**reasoning:** `typing.Optional[str]` â€” The reasoning for the assigned score.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.score.<a href="src/scorecard/score/client.py">update</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Update a score
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.score.update(
    run_id=1,
    testrecord_id=1,
    score_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**run_id:** `int` â€” The run ID that created the test record to be scored.
    
</dd>
</dl>

<dl>
<dd>

**testrecord_id:** `int` â€” The ID of the testrecord whose score will be updated.
    
</dd>
</dl>

<dl>
<dd>

**score_id:** `int` â€” The ID of the score to be updated.
    
</dd>
</dl>

<dl>
<dd>

**int_score:** `typing.Optional[int]` â€” The new integer score to assign.
    
</dd>
</dl>

<dl>
<dd>

**binary_score:** `typing.Optional[bool]` â€” The new boolean score to assign.
    
</dd>
</dl>

<dl>
<dd>

**reasoning:** `typing.Optional[str]` â€” The reasoning for the score update.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## RunMetric
<details><summary><code>client.run_metric.<a href="src/scorecard/run_metric/client.py">get</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve metrics associated with a run
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.run_metric.get(
    run_id=1,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**run_id:** `int` â€” The id of the run to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Tracing
<details><summary><code>client.tracing.<a href="src/scorecard/tracing/client.py">traces</a>()</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve traces
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.tracing.traces()

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.tracing.<a href="src/scorecard/tracing/client.py">trace</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve specified trace
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.tracing.trace(
    trace_id="trace_id",
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**trace_id:** `str` â€” The ID of the trace to retrieve spans from.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.tracing.<a href="src/scorecard/tracing/client.py">span</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve specified span
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.tracing.span(
    trace_id="trace_id",
    span_id="span_id",
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**trace_id:** `str` â€” The ID of the trace which the span is a part of.
    
</dd>
</dl>

<dl>
<dd>

**span_id:** `str` â€” The ID of the span to retrieve.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## Prompt
<details><summary><code>client.prompt.<a href="src/scorecard/prompt/client.py">get_by_name</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve a prod prompt by name
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.prompt.get_by_name(
    name="name",
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**name:** `str` â€” Name of the prompt.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.prompt.<a href="src/scorecard/prompt/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Two types of prompts can be created - a root prompt or a child prompt (aka Prompt Version in app).

        A root prompt can be created by providing the `name` param, and it will always be tagged as prod.

        A child prompt can be created by providing the `parent_id` param. Note that the `name` param in this case will be ignored as all descendents from a root prompt would share the root's name. `is_prod` can also be provided to configure whether a child should be tagged as prod.
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.prompt.create(
    prompt_template="<system>\nYou are a helpful assistant. Use the provided context to answer the user's query.\n\nContext: {context}\n</system>\n\n<user>\n{user_query}\n</user>",
    parent_id="7ac3cbd5-3b99-4e72-97f3-9cd2e749cace",
    description="Description of the prompt",
    model_params={
        "param1": "value1",
        "param2": 0.1,
        "param3": 100,
        "param4": True,
    },
    is_prod=True,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**prompt_template:** `str` 
    
</dd>
</dl>

<dl>
<dd>

**name:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**parent_id:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**description:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**model_params:** `typing.Optional[
    typing.Dict[str, typing.Optional[PromptCreateParamsModelParamsValue]]
]` 
    
</dd>
</dl>

<dl>
<dd>

**is_prod:** `typing.Optional[bool]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.prompt.<a href="src/scorecard/prompt/client.py">get</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve a prompt by id
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.prompt.get(
    id="id",
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**id:** `str` â€” The id of the prompt to get.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.prompt.<a href="src/scorecard/prompt/client.py">delete</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Delete a scoring config.
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.prompt.delete(
    id="id",
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**id:** `str` â€” The id of the scoring config to delete.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.prompt.<a href="src/scorecard/prompt/client.py">update</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Update a prompt.

        `is_prod` tags the provided prompt as the production prompt within the prompt graph.
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.prompt.update(
    id="id",
    is_prod=True,
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**id:** `str` â€” The id of the prompt to update.
    
</dd>
</dl>

<dl>
<dd>

**is_prod:** `typing.Optional[bool]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

## ScoringConfig
<details><summary><code>client.scoring_config.<a href="src/scorecard/scoring_config/client.py">create</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Create a new scoring config.
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.scoring_config.create(
    name="Scoring Config Name",
    description="Description of the scoring config",
    metrics=[1, 2, 3],
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**name:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**description:** `typing.Optional[str]` 
    
</dd>
</dl>

<dl>
<dd>

**metrics:** `typing.Optional[typing.Sequence[int]]` 
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

<details><summary><code>client.scoring_config.<a href="src/scorecard/scoring_config/client.py">get</a>(...)</code></summary>
<dl>
<dd>

#### ğŸ“ Description

<dl>
<dd>

<dl>
<dd>

Retrieve a scoring config by id
</dd>
</dl>
</dd>
</dl>

#### ğŸ”Œ Usage

<dl>
<dd>

<dl>
<dd>

```python
from scorecard import Scorecard

client = Scorecard(
    api_key="YOUR_API_KEY",
)
client.scoring_config.get(
    id="id",
)

```
</dd>
</dl>
</dd>
</dl>

#### âš™ï¸ Parameters

<dl>
<dd>

<dl>
<dd>

**id:** `str` â€” The id of the scoring config to get.
    
</dd>
</dl>

<dl>
<dd>

**request_options:** `typing.Optional[RequestOptions]` â€” Request-specific configuration.
    
</dd>
</dl>
</dd>
</dl>


</dd>
</dl>
</details>

